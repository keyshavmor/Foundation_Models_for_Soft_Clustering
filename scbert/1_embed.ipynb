{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e48b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from performer_pytorch import PerformerLM\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from utils import *\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972f9a1b-7d2a-4bfd-881c-898824906c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS = 7\n",
    "SEED = 2021\n",
    "EPOCHS = 1\n",
    "SEQ_LEN = 16906 + 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007090a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36763, 16906)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/adata_preprocessed_4000.h5ad'\n",
    "adata = sc.read_h5ad(data_path)\n",
    "data = adata.X\n",
    "print(type(data))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b158503-542d-4dec-9a6a-32b9b86579a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get position of genes for which we have correspondance in our data\n",
    "non_zero_columns = (adata.X.toarray() != 0).any(axis=0)\n",
    "non_zero_columns = np.append(non_zero_columns, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e96e759-2a35-4c5b-9bda-053e9891b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agauthier/scbert/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2485.)\n",
      "  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"
     ]
    }
   ],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = True\n",
    ")\n",
    "\n",
    "path = 'model/scbert_pretrain.pth'\n",
    "ckpt = torch.load(path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scbert_embed(data):\n",
    "    batch_size = data.shape[0]\n",
    "    model.eval()\n",
    "    batch = []\n",
    "    epoch = []\n",
    "    with torch.no_grad():\n",
    "        for index in tqdm(range(batch_size)):\n",
    "            full_seq = data[index].toarray()[0]\n",
    "            full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n",
    "            full_seq = torch.from_numpy(full_seq).long()\n",
    "            full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n",
    "            full_seq = full_seq.unsqueeze(0)\n",
    "            cell_embedding = model(full_seq, return_encodings = True, output_attentions = False)\n",
    "            cell_embedding = torch.reshape(cell_embedding, [16907, 200])\n",
    "            cell_embedding = cell_embedding[non_zero_columns, :]\n",
    "            batch.append(cell_embedding)\n",
    "            if index % 500 == 0:\n",
    "                #regularly empty GPU of data\n",
    "                epoch.extend([b.cpu() for b in batch])\n",
    "                batch = []\n",
    "        epoch.extend([b.cpu() for b in batch])\n",
    "    embeddings = np.stack([t.numpy().astype(np.float16) for t in epoch])\n",
    "    return embeddings\n",
    "\n",
    "def get_cuts(N, k):\n",
    "    return [i * N // k for i in range(1, k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25fc1657-095e-4724-9dc1-f0eb3427c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3676, 7352, 11028, 14705, 18381, 22057, 25734, 29410, 33086]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_batch = 10\n",
    "batch_cut = get_cuts(36763, number_of_batch)\n",
    "batch_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd8a312-6e54-4756-8f50-e69074ec8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "batch : 0-3676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb134d490ba481c954f98d4244e88d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3676, 2455, 200)\n",
      "1\n",
      "batch : 3676-7352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f54cf794ba94882a8df06d96c5200ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3676, 2455, 200)\n",
      "2\n",
      "batch : 7352-11028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1fde32c47f427998a1c5325b7a9566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m data[batch_cut[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:batch_cut[i]]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_cut[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_cut[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mscbert_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/embeddings_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36mscbert_embed\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m cell_embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(cell_embedding, [\u001b[38;5;241m16907\u001b[39m, \u001b[38;5;241m200\u001b[39m])\n\u001b[1;32m     15\u001b[0m cell_embedding \u001b[38;5;241m=\u001b[39m cell_embedding[non_zero_columns, :]\n\u001b[0;32m---> 16\u001b[0m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#regularly empty GPU of data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     epoch\u001b[38;5;241m.\u001b[39mextend([b\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(number_of_batch):\n",
    "    print(i)\n",
    "    if i == 0:\n",
    "        batch_data = data[:batch_cut[i]]\n",
    "        print(f'batch : {0}-{batch_cut[i]}')\n",
    "    elif i == len(batch_cut):\n",
    "        batch_data = data[batch_cut[i-1]:]\n",
    "        print(f'batch : {batch_cut[i-1]}-{data.shape[0]}')\n",
    "    else:\n",
    "        batch_data = data[batch_cut[i-1]:batch_cut[i]]\n",
    "        print(f'batch : {batch_cut[i-1]}-{batch_cut[i]}')\n",
    "    embeddings = scbert_embed(batch_data)\n",
    "    print(embeddings.shape)\n",
    "    path = 'data/embeddings_' + str(i) + '.npy'\n",
    "    np.save(path, embeddings)\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
